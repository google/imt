---
title: "Bayesian Linear Model"
output: rmarkdown::html_vignette
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)
```

## Motivation

Ordinary Least Squares (OLS) is a popular frequentist approach for linear
 regression. It aims to find the line that minimizes the sum of squared
 differences between the observed and predicted values of the dependent
 variable. In this framework, the model parameters (beta coefficients) are
 considered fixed but unknown. OLS estimates these parameters by minimizing
 the sum of squared residuals, leading to point estimates and confidence
 intervals for each coefficient. Inference focuses on hypothesis testing and
 p-values to assess the significance of the relationships between independent
 and dependent variables.

The Bayesian linear model is similar to OLS in structure, but adopts a 
 different perspective on the parameters. Instead of fixed values, 
 they are treated as random variables with probability distributions
 reflecting uncertainty. Prior distributions are incorporated based on existing
 knowledge or assumptions about the parameters. The model estimates the
 posterior distribution of the parameters by combining the prior information
 with the observed data via Bayes' theorem. This yields a range of plausible
 values for each coefficient, along with their associated probabilities.
 Inference emphasizes credible intervals and posterior probabilities to quantify
 uncertainty and interpret the strength of evidence for relationships in the data.

This package fits a Bayesian linear model using
 [weakly informative priors](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)
 for the covariates and allows the user to set the prior for the impact of
 the intervention. In particular, if y is the outcome of interest:

$$
\begin{aligned}
y & \sim N(\mu, \sigma) \\
\mu &= \alpha + X^\star\beta + \color{red}{\eta} t
\end{aligned}
$$

We standardize the data as follows:

$$
\begin{aligned}
y^\star & = \frac{y - \mu_y}{\sigma_y} \\
 & \sim N(\mu^\star, \sigma^\star) \\
\mu^\star & = \alpha^\star + \frac{X - \mu_X}{\sigma_X} \beta^\star +
 \eta^\star t \\
 \alpha^\star & \sim N(0,1) \\
 \beta^\star & \sim N(0,1) \\
 \color{red}{\eta^\star} & \color{red}{\sim N(\mu_\eta, \sigma_\eta)} \\
 \sigma^\star & \sim N^+(0,1) \\
\end{aligned}
$$


Therefore

$$
\begin{aligned}
\frac{y - \mu_y}{\sigma_y} & = \alpha^\star +
\frac{X - \mu_X}{\sigma_X} \beta^\star + \eta^\star t \\
y & = (\alpha^\star +
\frac{X - \mu_X}{\sigma_X} \beta^\star + \eta^\star t) \sigma_y + \mu_y \\
\color{red}\eta = \eta^\star \sigma_y
\end{aligned}
$$


Notice that if you have better priors, you should use them.

## Demonstration

First, we will create some fake data that we will feed to out linear Bayesian
 model to generate a fake dataset based on these data and random parameters that
 will determine the outcome of interest.

```{r setup}
library(im)
```

```{r sample_data}
set.seed(8297)
N <- 500

fake_data <- tibble::tibble(
  y_pre = rnorm(n = N, mean = 11739, sd = 100),
  x1 = rnorm(n = N, mean = -200, sd = 10),
  x2 = rnorm(n = N, mean = 300, sd = 100),
  x3 = sample(c("a", "b", "c"), size = N, replace = TRUE),
  t = sample(c(FALSE, TRUE), size = N, replace = TRUE),
  y = rnorm(n = N, mean = 0, sd = 1) # This is just a placeholder for now
)
```

To generate the fake dataset, we feed the data we just generated to `im:blm` and
 set `generate_fake_data = 1`. This will allow us to see how well the model
 can recover the parameters of interest.

```{r blm, results="hide"}
blm_fake <- im::blm$new(
  y = "y", x = c("y_pre", "x1", "x2", "x3"),
  treatment = "t", data = fake_data, eta_mean = 0,
  eta_sd = 1, generate_fake_data = 1
)
```

Under the hood, the model is drawing from the prior and randomly choosing one
 of those draws as the truth. Then, the model is fitted to that
 synthetic data to see if we can recover the parameter of interest. In this
 case the true treatment effect is
 `r round(blm_fake$.__enclos_env__$private$..true_eta, 2)` 

### Diagnostics

It is always a good idea to look at the traceplot. A traceplot is a diagnostic
 tool used to visualize the "path" that a Markov Chain Monte Carlo (MCMC)
 sampler takes as it explores the parameter space. It helps assess the
 convergence and mixing of the chains, which is crucial for ensuring
 reliable inference from the model.

```{r tracePlot}
blm_fake$tracePlot()
```

1. Assessing Convergence:

A well-converged chain should exhibit a "hairy caterpillar" pattern, 
 where the trace fluctuates around a stable value without any trends or drifts. 
 This indicates that the sampler has adequately explored the parameter space 
 and reached a stationary distribution.

Conversely, non-converging chains might show trends, jumps, or slow mixing, 
 suggesting that the sampler is stuck in a local region or hasn't adequately 
 explored the posterior distribution. Inferences drawn from such chains can be 
 unreliable and misleading.

2. Diagnosing Mixing:

Good mixing implies that the chains effectively explore the entire parameter 
 space and don't get stuck in local regions. This is visually represented by
 well-intertwined lines from different chains on the traceplot.

Poorly mixed chains show distinct separation among lines, indicating they
 haven't adequately explored the entire posterior distribution.
 This can lead to biased and inaccurate estimates of the parameters and
 their uncertainty.

3. Identifying Issues:

Traceplots can reveal potential issues in the model specification, priors, 
 or MCMC settings. For example, highly correlated parameters might exhibit 
 synchronized movement in the traceplot, suggesting a dependence relationship 
 that needs further investigation.
Overall, examining traceplots is a valuable diagnostic step in Bayesian
 statistical analysis. They provide valuable insights into the convergence
  and mixing of MCMC chains, aiding in the valid and reliable interpretation
   of the model results.

It is prudent to verify that our model's data generating process is compatible
 with the data used to fit the model. To do this, we can compare the kernel
 density of draws from the posterior distribution to the density of our data.

```{r ppcDensOverlay}
blm_fake$ppcDensOverlay(n = 50)
```

Finally, you can use the following methods to summarize your findings:

* `blm_fake$vizdraws()`: Plots effect's prior and posterior distributions.
* `blm_fake$priorInterval()`: Calculates the prior for the effect of the intervention
 based on the hyperpriors.
* `blm_fake$credibleInterval()`: Calculates credible interval for the effect of the intervention
* `blm_fake$pointEstimate()`: Returns the median (or mean) of the posterior 
distribution of the treatment effect.

---

#### im

Licensed under the Apache License, Version 2.0.\
